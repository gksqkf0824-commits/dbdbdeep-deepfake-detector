from fastapi import FastAPI, UploadFile, File, HTTPException, Form
from fastapi.middleware.cors import CORSMiddleware
import secrets
import base64
import os
import mimetypes
import tempfile
import uuid
from typing import Any, Dict, Optional
from urllib.parse import urlparse

import cv2
import numpy as np
import requests
try:
    import yt_dlp
except Exception:
    yt_dlp = None

from model import detector
from redis_client import redis_db

from utils import (
    sha256_bytes,
    redis_get_json,
    redis_set_json,
    video_to_uniform_sampled_frames,
    aggregate_scores,
    trimmed_mean_confidence,
    build_analysis_result,
    detect_faces_with_aligned_crops,
    get_cam_target_layer,
    GradCAM,
    build_evidence_for_face,
    explain_from_evidence,
    generate_video_ai_comment,
)

app = FastAPI()

# --- Redis ì—°ê²° ì²´í¬ ---
@app.on_event("startup")
def check_redis_connection():
    try:
        redis_db.ping()
        print("âœ… Redis ì—°ê²° ì„±ê³µ! (ì¤€ë¹„ ì™„ë£Œ)")
    except Exception as e:
        print(f"âŒ Redis ì—°ê²° ì‹¤íŒ¨: {e}")
        print("   ğŸ‘‰ Dockerê°€ ì¼œì ¸ ìˆëŠ”ì§€, 'docker run -p 6379:6379 -d redis'ë¥¼ í–ˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”!")

# --- CORS ---
# NOTE: allow_credentials=True + allow_origins=["*"] ì¡°í•©ì€ ë¸Œë¼ìš°ì €/í™˜ê²½ì— ë”°ë¼ ë¬¸ì œê°€ ë  ìˆ˜ ìˆìŒ.
# (ì¼ë‹¨ ê¸°ì¡´ ìœ ì§€. ìš´ì˜ì—ì„œëŠ” ë„ë©”ì¸ì„ ëª…ì‹œí•˜ëŠ” ê²Œ ì•ˆì „)
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# --- Configuration ---
REAL_MEAN = 15.0
REAL_STD = 8.0

# Video sampling
VIDEO_MAX_SIDE = 640
VIDEO_MIN_FRAMES = 12
VIDEO_MAX_FRAMES_CAP = 48
VIDEO_FRAMES_PER_MINUTE = 24

# Aggregation
AGG_MODE_VIDEO = "mean"
TOPK = 5
VIDEO_TRIM_RATIO = 0.10

# Redis TTL
RESULT_TTL_SEC = 3600
CACHE_TTL_SEC = 24 * 3600
REMOTE_IMAGE_MAX_BYTES = 10 * 1024 * 1024
REMOTE_VIDEO_MAX_BYTES = 200 * 1024 * 1024
REMOTE_IMAGE_TIMEOUT_SEC = 10
REMOTE_VIDEO_TIMEOUT_SEC = 45
YTDLP_COOKIEFILE = (os.getenv("YTDLP_COOKIEFILE") or "").strip()
REMOTE_COMMON_HEADERS = {
    "User-Agent": (
        "Mozilla/5.0 (X11; Linux x86_64) "
        "AppleWebKit/537.36 (KHTML, like Gecko) "
        "Chrome/122.0.0.0 Safari/537.36"
    ),
    "Accept-Language": "ko-KR,ko;q=0.9,en-US;q=0.8,en;q=0.7",
}
IMAGE_EXTS = {".jpg", ".jpeg", ".png", ".bmp", ".gif", ".webp", ".tif", ".tiff"}
VIDEO_EXTS = {".mp4", ".mov", ".webm", ".mkv", ".avi", ".m4v"}


def store_result_and_make_response(analysis_result: dict, stored_result: dict = None) -> dict:
    """
    ê²°ê³¼ë¥¼ Redis(res:{token})ì— ì €ì¥í•˜ê³  í”„ë¡ íŠ¸ê°€ ì“°ëŠ” í˜•íƒœë¡œ ë°˜í™˜.
    """
    token = secrets.token_urlsafe(16)
    payload_for_store = stored_result if stored_result is not None else analysis_result
    redis_set_json(redis_db, f"res:{token}", payload_for_store, ex=RESULT_TTL_SEC)
    return {
        "result_url": f"http://127.0.0.1:8000/get-result/{token}",
        "data": analysis_result,
    }


def has_frame_series(payload: dict, key: str) -> bool:
    values = payload.get(key)
    return isinstance(values, list) and len(values) >= 2


def delete_keys_by_patterns(patterns, batch_size: int = 500) -> int:
    deleted_total = 0

    for pattern in patterns:
        batch = []
        for key in redis_db.scan_iter(match=pattern, count=1000):
            batch.append(key)
            if len(batch) >= batch_size:
                deleted_total += int(redis_db.delete(*batch))
                batch.clear()

        if batch:
            deleted_total += int(redis_db.delete(*batch))

    return deleted_total


def _validate_evidence_level(level: str) -> str:
    lv = (level or "mvp").strip().lower()
    if lv not in {"off", "mvp", "full"}:
        raise HTTPException(status_code=400, detail="evidence_levelì€ off/mvp/full ì¤‘ í•˜ë‚˜ì—¬ì•¼ í•©ë‹ˆë‹¤.")
    return lv


def _safe_score_agg(values):
    return float(max(values)) if values else 0.0


def _bytes_to_data_url(payload: bytes, mime_type: str) -> str:
    b64 = base64.b64encode(payload).decode("utf-8")
    return f"data:{mime_type};base64,{b64}"


def _frame_to_preview_data_url(frame_bgr: np.ndarray) -> str:
    ok, buf = cv2.imencode(".jpg", frame_bgr, [int(cv2.IMWRITE_JPEG_QUALITY), 85])
    if not ok:
        raise ValueError("í”„ë¦¬ë·° í”„ë ˆì„ ì¸ì½”ë”© ì‹¤íŒ¨")
    return _bytes_to_data_url(buf.tobytes(), "image/jpeg")


def _read_response_content_limited(resp: requests.Response, max_bytes: int) -> bytes:
    chunks = []
    total = 0
    for chunk in resp.iter_content(chunk_size=1024 * 512):
        if not chunk:
            continue
        total += len(chunk)
        if total > int(max_bytes):
            raise HTTPException(status_code=413, detail=f"ë‹¤ìš´ë¡œë“œ íŒŒì¼ì´ ë„ˆë¬´ í½ë‹ˆë‹¤. (ìµœëŒ€ {max_bytes // (1024 * 1024)}MB)")
        chunks.append(chunk)
    return b"".join(chunks)


def _filename_from_url(url: str, fallback: str = "media.bin") -> str:
    parsed = urlparse(url)
    name = os.path.basename(parsed.path or "").strip()
    return name or fallback


def _is_likely_social_video_url(url: str) -> bool:
    host = (urlparse(url).netloc or "").lower()
    return any(domain in host for domain in ("youtube.com", "youtu.be", "instagram.com"))


def _is_likely_ext(path: str, ext_set: set) -> bool:
    path = (path or "").lower()
    return any(path.endswith(ext) for ext in ext_set)


def _pick_ytdlp_primary_info(info: dict) -> dict:
    if isinstance(info, dict) and str(info.get("_type", "")).lower() == "playlist":
        entries = info.get("entries") or []
        for entry in entries:
            if isinstance(entry, dict):
                return entry
    return info if isinstance(info, dict) else {}


def _resolve_ytdlp_downloaded_path(ydl: Any, info: dict, workdir: str) -> Optional[str]:
    requested = info.get("requested_downloads")
    if isinstance(requested, list):
        for item in requested:
            if not isinstance(item, dict):
                continue
            cand = item.get("filepath") or item.get("_filename")
            if isinstance(cand, str) and os.path.exists(cand):
                return cand

    try:
        cand = ydl.prepare_filename(info)
        if isinstance(cand, str) and os.path.exists(cand):
            return cand
    except Exception:
        pass

    candidates = []
    for root, _, files in os.walk(workdir):
        for name in files:
            path = os.path.join(root, name)
            try:
                size = os.path.getsize(path)
            except OSError:
                continue
            candidates.append((size, path))
    if not candidates:
        return None
    candidates.sort(key=lambda x: x[0], reverse=True)
    return candidates[0][1]


def _humanize_ytdlp_error(raw_msg: str) -> str:
    msg = (raw_msg or "").strip()
    low = msg.lower()

    if "unsupported url" in low:
        return "ì§€ì›í•˜ì§€ ì•ŠëŠ” URLì…ë‹ˆë‹¤. ì›ë³¸ ì´ë¯¸ì§€/ì˜ìƒ ë§í¬ ë˜ëŠ” ê³µê°œëœ Shorts/Reels ë§í¬ë¥¼ ì…ë ¥í•´ ì£¼ì„¸ìš”."
    if "sign in to confirm you're not a bot" in low:
        return (
            "YouTubeê°€ ìë™í™” ì ‘ê·¼ì„ ì°¨ë‹¨í–ˆìŠµë‹ˆë‹¤. "
            "ì„œë²„ì— yt-dlp cookie ì„¤ì •(ì˜ˆ: cookiefile)ì„ ì¶”ê°€í•˜ê±°ë‚˜ ë‹¤ë¥¸ ê³µê°œ URLë¡œ ì‹œë„í•´ ì£¼ì„¸ìš”."
        )
    if "instagram" in low and "unable to extract video url" in low:
        return (
            "Instagram URLì—ì„œ ì˜ìƒ ì£¼ì†Œë¥¼ ì¶”ì¶œí•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. "
            "ê³µê°œ ê²Œì‹œë¬¼ì¸ì§€ í™•ì¸í•˜ê³ , í•„ìš” ì‹œ ì„œë²„ì˜ yt-dlp/cookie ì„¤ì •ì„ ì ê²€í•´ ì£¼ì„¸ìš”."
        )
    return msg or "ì•Œ ìˆ˜ ì—†ëŠ” yt-dlp ì˜¤ë¥˜"


def _pick_stream_url_from_info(info: dict) -> Optional[str]:
    if not isinstance(info, dict):
        return None

    direct = info.get("url")
    if isinstance(direct, str) and direct.strip():
        return direct.strip()

    formats = info.get("formats")
    if isinstance(formats, list):
        # progressive(mp4) í˜•íƒœë¥¼ ìš°ì„  ì„ íƒ, ì—†ìœ¼ë©´ ê°€ì¥ í° ë¹„íŠ¸ë ˆì´íŠ¸ í›„ë³´ ì‚¬ìš©.
        scored = []
        for fmt in formats:
            if not isinstance(fmt, dict):
                continue
            cand = fmt.get("url")
            if not isinstance(cand, str) or not cand.strip():
                continue
            ext = str(fmt.get("ext") or "").lower()
            vcodec = str(fmt.get("vcodec") or "")
            acodec = str(fmt.get("acodec") or "")
            tbr = float(fmt.get("tbr") or 0.0)
            prefer_progressive = 1 if vcodec != "none" and acodec != "none" else 0
            prefer_mp4 = 1 if ext == "mp4" else 0
            scored.append(((prefer_progressive, prefer_mp4, tbr), cand.strip()))
        if scored:
            scored.sort(key=lambda x: x[0], reverse=True)
            return scored[0][1]
    return None


def _download_remote_bytes(url: str, timeout_sec: int, max_bytes: int) -> tuple[bytes, str]:
    with requests.get(
        url,
        stream=True,
        timeout=timeout_sec,
        allow_redirects=True,
        headers=REMOTE_COMMON_HEADERS,
    ) as resp:
        resp.raise_for_status()
        content_type = (resp.headers.get("content-type") or "").split(";")[0].strip().lower()
        data = _read_response_content_limited(resp, max_bytes)
    if not data:
        raise HTTPException(status_code=400, detail="ë‹¤ìš´ë¡œë“œí•œ ë¯¸ë””ì–´ ë°ì´í„°ê°€ ë¹„ì–´ ìˆìŠµë‹ˆë‹¤.")
    return data, content_type


def _download_media_with_ytdlp(url: str) -> Dict[str, Any]:
    if yt_dlp is None:
        raise HTTPException(
            status_code=500,
            detail="yt-dlpê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. backend/requirements.txt ì„¤ì¹˜ í›„ ë‹¤ì‹œ ì‹œë„í•´ ì£¼ì„¸ìš”.",
        )

    with tempfile.TemporaryDirectory(prefix="url_media_") as tmp_dir:
        outtmpl = os.path.join(tmp_dir, "%(id)s.%(ext)s")
        base_opts = {
            "quiet": True,
            "no_warnings": True,
            "noplaylist": True,
            "socket_timeout": REMOTE_VIDEO_TIMEOUT_SEC,
            "outtmpl": outtmpl,
            "restrictfilenames": True,
            "merge_output_format": "mp4",
            "geo_bypass": True,
            "retries": 2,
            "extractor_retries": 2,
            "fragment_retries": 2,
            "http_headers": REMOTE_COMMON_HEADERS,
            "extractor_args": {"youtube": {"player_client": ["android", "web"]}},
        }
        if YTDLP_COOKIEFILE and os.path.exists(YTDLP_COOKIEFILE):
            base_opts["cookiefile"] = YTDLP_COOKIEFILE
        # í”Œë«í¼/ì½”ë± ì¡°í•©ë³„ë¡œ í¬ë§· ê°€ìš©ì„±ì´ ë‹¤ë¥¼ ìˆ˜ ìˆì–´ ìˆœì°¨ fallback.
        format_candidates = [
            "bestvideo*+bestaudio/best",
            "best/bestvideo+bestaudio",
            None,
        ]

        info = {}
        downloaded_path = None
        cert_error_seen = False
        last_exc: Optional[Exception] = None

        for fmt in format_candidates:
            attempt_opts = dict(base_opts)
            if fmt:
                attempt_opts["format"] = fmt
            if cert_error_seen:
                # ëŸ°íƒ€ì„ CA ì²´ì¸ ì´ìŠˆê°€ ìˆëŠ” í™˜ê²½ fallback.
                attempt_opts["nocheckcertificate"] = True

            try:
                with yt_dlp.YoutubeDL(attempt_opts) as ydl:
                    raw_info = ydl.extract_info(url, download=True)
                    info = _pick_ytdlp_primary_info(raw_info)
                    downloaded_path = _resolve_ytdlp_downloaded_path(ydl, info, tmp_dir)
                if downloaded_path and os.path.exists(downloaded_path):
                    break
            except Exception as exc:
                last_exc = exc
                msg = str(exc)
                if "CERTIFICATE_VERIFY_FAILED" in msg or "certificate verify failed" in msg.lower():
                    cert_error_seen = True
                continue

        if not downloaded_path or not os.path.exists(downloaded_path):
            # ì¼ë¶€ í™˜ê²½ì—ì„œëŠ” download=Trueë§Œ ì‹¤íŒ¨í•˜ê³  metadata ì¶”ì¶œ(download=False)ì€ ê°€ëŠ¥í•œ ê²½ìš°ê°€ ìˆì–´ fallback ì‹œë„.
            try:
                fallback_opts = dict(base_opts)
                fallback_opts["skip_download"] = True
                fallback_opts["format"] = "best[ext=mp4]/best"
                with yt_dlp.YoutubeDL(fallback_opts) as ydl:
                    raw_info = ydl.extract_info(url, download=False)
                    info = _pick_ytdlp_primary_info(raw_info)
                stream_url = _pick_stream_url_from_info(info)
                if stream_url:
                    ext = str(info.get("ext") or "").lower()
                    vcodec = str(info.get("vcodec") or "").lower()
                    is_video = (vcodec not in {"", "none"}) or (f".{ext}" in VIDEO_EXTS)
                    max_bytes = REMOTE_VIDEO_MAX_BYTES if is_video else REMOTE_IMAGE_MAX_BYTES
                    timeout = REMOTE_VIDEO_TIMEOUT_SEC if is_video else REMOTE_IMAGE_TIMEOUT_SEC
                    media_bytes, content_type = _download_remote_bytes(stream_url, timeout, max_bytes)
                    mime_type = content_type or (f"video/{ext}" if is_video and ext else f"image/{ext}" if ext else "")
                    if is_video and not mime_type.startswith("video/"):
                        mime_type = "video/mp4"
                    if (not is_video) and not mime_type.startswith("image/"):
                        mime_type = "image/jpeg"
                    thumbnail_url = info.get("thumbnail") if isinstance(info, dict) else None
                    title = str(info.get("title") or "").strip() if isinstance(info, dict) else ""
                    return {
                        "media_type": "video" if is_video else "image",
                        "mime_type": mime_type,
                        "bytes": media_bytes,
                        "filename": _filename_from_url(url, fallback=f"downloaded_media.{ext or 'bin'}"),
                        "preview": {
                            "kind": "video" if is_video else "image",
                            "url": stream_url,
                            "thumbnail_url": str(thumbnail_url or "").strip() or None,
                            "page_url": url,
                            "title": title or None,
                        },
                    }
            except Exception:
                pass

            if last_exc is not None:
                user_msg = _humanize_ytdlp_error(str(last_exc))
                raise HTTPException(status_code=400, detail=f"URL ë¯¸ë””ì–´ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨(yt-dlp): {user_msg}") from last_exc
            raise HTTPException(status_code=400, detail="yt-dlp ë‹¤ìš´ë¡œë“œ ê²°ê³¼ íŒŒì¼ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")

        # cert ì˜¤ë¥˜ë¥¼ ê²ªì€ ê²½ìš°, ë§ˆì§€ë§‰ fallbackë¡œ ì¸ì¦ì„œ ê²€ì¦ ë¹„í™œì„±í™” 1íšŒ ì¬ì‹œë„
        # (ìƒë‹¨ í¬ë§· ë£¨í”„ì—ì„œ cert_error_seen ì‹œ ì´ë¯¸ nocheckcertificate=True ë¡œ ì¬ì‹œë„ë¨)

        mime_type, _ = mimetypes.guess_type(downloaded_path)
        mime_type = str(mime_type or "").lower()
        ext = os.path.splitext(downloaded_path)[1].lower()
        is_video = mime_type.startswith("video/") or ext in {".mp4", ".mov", ".webm", ".mkv", ".avi", ".m4v"}
        media_type = "video" if is_video else "image"

        file_size = os.path.getsize(downloaded_path)
        size_limit = REMOTE_VIDEO_MAX_BYTES if is_video else REMOTE_IMAGE_MAX_BYTES
        if file_size > size_limit:
            raise HTTPException(
                status_code=413,
                detail=f"ë‹¤ìš´ë¡œë“œ íŒŒì¼ì´ ë„ˆë¬´ í½ë‹ˆë‹¤. ({size_limit // (1024 * 1024)}MB ì´í•˜)",
            )

        with open(downloaded_path, "rb") as f:
            media_bytes = f.read()

        stream_url = info.get("url") if isinstance(info, dict) else None
        thumbnail_url = info.get("thumbnail") if isinstance(info, dict) else None
        title = str(info.get("title") or "").strip() if isinstance(info, dict) else ""

        return {
            "media_type": media_type,
            "mime_type": mime_type,
            "bytes": media_bytes,
            "filename": os.path.basename(downloaded_path),
            "preview": {
                "kind": media_type,
                "url": str(stream_url or "").strip() or None,
                "thumbnail_url": str(thumbnail_url or "").strip() or None,
                "page_url": url,
                "title": title or None,
            },
        }


def _analyze_evidence_bytes(
    image_bytes: bytes,
    explain: bool = True,
    evidence_level: str = "mvp",
    fusion_w: float = 0.5,
    source_preview: Optional[Dict[str, Any]] = None,
    input_media_type: str = "image",
) -> dict:
    request_id = str(uuid.uuid4())
    lv = _validate_evidence_level(evidence_level)

    img_arr = np.frombuffer(image_bytes, np.uint8)
    bgr = cv2.imdecode(img_arr, cv2.IMREAD_COLOR)
    if bgr is None:
        raise HTTPException(status_code=400, detail="ì´ë¯¸ì§€ ë””ì½”ë”© ì‹¤íŒ¨")

    rgb_model = detector.pixel_model
    freq_model = detector.freq_model
    if rgb_model is None or freq_model is None:
        raise HTTPException(
            status_code=500,
            detail="RGB/Frequency ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: backend/models/*.pth ê²½ë¡œë¥¼ í™•ì¸í•˜ì„¸ìš”.",
        )

    try:
        faces = detect_faces_with_aligned_crops(
            image_bgr=bgr,
            margin=0.15,
            target_size=224,
            max_faces=1,
            prioritize_frontal=True,
        )
    except Exception as exc:
        raise HTTPException(status_code=500, detail=f"ì–¼êµ´ ë¶„ì„ ì‹¤íŒ¨: {exc}") from exc

    if not faces:
        no_face_result = {
            "request_id": request_id,
            "status": "ok",
            "score": {"p_rgb": 0.0, "p_freq": 0.0, "p_final": 0.0},
            "faces": [],
            "ai_comment": "ì–¼êµ´ì´ ì„ ëª…í•˜ê²Œ ë³´ì´ì§€ ì•Šì•„ íŒë…ì„ ì§„í–‰í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ì–¼êµ´ì´ í¬ê²Œ ë³´ì´ëŠ” ì´ë¯¸ì§€ë¡œ ë‹¤ì‹œ ì‹œë„í•´ ì£¼ì„¸ìš”.",
            "ai_comment_source": "fallback:no_face",
        }
        no_face_result["input_media_type"] = str(input_media_type or "image")
        if source_preview:
            no_face_result["source_preview"] = source_preview
        return no_face_result

    cam_target_layer = get_cam_target_layer(rgb_model)
    cam = GradCAM(rgb_model, cam_target_layer)

    faces_out = []
    p_rgb_list, p_freq_list, p_final_list = [], [], []

    try:
        for i, face in enumerate(faces):
            out = build_evidence_for_face(
                face_rgb_uint8=face["crop_rgb"],
                landmarks=face["landmarks"],
                rgb_model=rgb_model,
                freq_model=freq_model,
                cam=cam,
                fusion_w=float(fusion_w),
                evidence_level=lv,
            )

            score = out["score"]
            evidence = out["evidence"]
            assets = out["assets"]

            p_rgb_list.append(float(score["p_rgb"]))
            p_freq_list.append(float(score["p_freq"]))
            p_final_list.append(float(score["p_final"]))

            item = {
                "face_id": i,
                "assets": assets,
                "evidence": evidence,
            }
            if explain:
                item["explanation"] = explain_from_evidence(
                    evidence=evidence,
                    score=score,
                    media_mode_hint="image",
                    use_openai=(i == 0),
                )

            faces_out.append(item)
    finally:
        cam.close()

    ai_comment = ""
    ai_comment_source = "rule_based"
    if explain and faces_out:
        first_explanation = faces_out[0].get("explanation", {})
        if isinstance(first_explanation, dict):
            ai_comment = str(first_explanation.get("summary", "")).strip()
            ai_comment_source = str(first_explanation.get("summary_source", "rule_based")).strip() or "rule_based"

    result = {
        "request_id": request_id,
        "status": "ok",
        "score": {
            "p_rgb": _safe_score_agg(p_rgb_list),
            "p_freq": _safe_score_agg(p_freq_list),
            "p_final": _safe_score_agg(p_final_list),
        },
        "faces": faces_out,
        "ai_comment": ai_comment,
        "ai_comment_source": ai_comment_source,
    }
    result["input_media_type"] = str(input_media_type or "image")
    if source_preview:
        result["source_preview"] = source_preview
    return result


@app.get("/test")
async def test():
    return {"message": "ì„œë²„ê°€ ì •ìƒì ìœ¼ë¡œ ì‘ë™ ì¤‘ì…ë‹ˆë‹¤."}


@app.post("/clear-cache")
async def clear_cache():
    """
    Redis ìºì‹œ í‚¤ ì‚­ì œ.
    í˜„ì¬ëŠ” ê²°ê³¼/ë¹„ë””ì˜¤ ìºì‹œë¥¼ ëª¨ë‘ ì •ë¦¬í•œë‹¤.
    """
    try:
        patterns = ["cache:*", "res:*"]
        deleted_count = delete_keys_by_patterns(patterns)
        return {
            "message": "Redis cache cleared",
            "deleted_keys": deleted_count,
            "patterns": patterns,
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Cache clear error: {e}")


@app.post("/api/analyze")
@app.post("/api/analyze-evidence")
@app.post("/analyze-evidence")
async def analyze_with_evidence(
    file: UploadFile = File(...),
    explain: bool = Form(True),
    evidence_level: str = Form("mvp"),
    fusion_w: float = Form(0.5),
):
    data = await file.read()
    return _analyze_evidence_bytes(
        image_bytes=data,
        explain=explain,
        evidence_level=evidence_level,
        fusion_w=fusion_w,
    )


@app.post("/api/analyze-url")
@app.post("/analyze-url")
async def analyze_url_with_evidence(
    image_url: Optional[str] = Form(None),
    url: Optional[str] = Form(None),
    explain: bool = Form(True),
    evidence_level: str = Form("mvp"),
    fusion_w: float = Form(0.5),
):
    raw_url = (image_url or url or "").strip()
    if not raw_url:
        raise HTTPException(status_code=400, detail="ë¶„ì„í•  URLì„ ì…ë ¥í•´ ì£¼ì„¸ìš”.")
    parsed = urlparse(raw_url)
    if parsed.scheme not in {"http", "https"} or not parsed.netloc:
        raise HTTPException(status_code=400, detail="ìœ íš¨í•œ http/https URLì„ ì…ë ¥í•˜ì„¸ìš”.")

    target_url = parsed.geturl()

    # 1) ì¼ë°˜ ì´ë¯¸ì§€/ë¹„ë””ì˜¤ ì§ë§í¬ëŠ” requestsë¡œ ìš°ì„  ì²˜ë¦¬
    if not _is_likely_social_video_url(target_url):
        try:
            with requests.get(
                target_url,
                stream=True,
                timeout=REMOTE_IMAGE_TIMEOUT_SEC,
                allow_redirects=True,
                headers=REMOTE_COMMON_HEADERS,
            ) as resp:
                resp.raise_for_status()
                content_type = (resp.headers.get("content-type") or "").lower()
                final_path = urlparse(str(resp.url or target_url)).path.lower()

                if content_type.startswith("image/") or _is_likely_ext(final_path, IMAGE_EXTS):
                    data = _read_response_content_limited(resp, REMOTE_IMAGE_MAX_BYTES)
                    if not data:
                        raise HTTPException(status_code=400, detail="ë‹¤ìš´ë¡œë“œí•œ ì´ë¯¸ì§€ ë°ì´í„°ê°€ ë¹„ì–´ ìˆìŠµë‹ˆë‹¤.")
                    mime = content_type.split(";")[0].strip() or "image/jpeg"
                    source_preview = {
                        "kind": "image",
                        "url": target_url,
                        "data_url": _bytes_to_data_url(data, mime),
                        "page_url": target_url,
                    }
                    return _analyze_evidence_bytes(
                        image_bytes=data,
                        explain=explain,
                        evidence_level=evidence_level,
                        fusion_w=fusion_w,
                        source_preview=source_preview,
                        input_media_type="image",
                    )

                if content_type.startswith("video/") or _is_likely_ext(final_path, VIDEO_EXTS):
                    data = _read_response_content_limited(resp, REMOTE_VIDEO_MAX_BYTES)
                    if not data:
                        raise HTTPException(status_code=400, detail="ë‹¤ìš´ë¡œë“œí•œ ì˜ìƒ ë°ì´í„°ê°€ ë¹„ì–´ ìˆìŠµë‹ˆë‹¤.")
                    source_preview = {
                        "kind": "video",
                        "url": target_url,
                        "page_url": target_url,
                    }
                    return _analyze_video_bytes(
                        content=data,
                        filename=_filename_from_url(target_url, fallback="remote_video.mp4"),
                        source_preview=source_preview,
                    )
        except HTTPException:
            raise
        except requests.RequestException:
            pass

    # 2) ì¸ìŠ¤íƒ€ ë¦´ìŠ¤ / ìœ íŠœë¸Œ ì‡¼ì¸  ë“±ì€ yt-dlpë¡œ ì²˜ë¦¬
    media = _download_media_with_ytdlp(target_url)
    media_type = str(media.get("media_type") or "").lower()
    payload = media.get("bytes") or b""
    filename = str(media.get("filename") or _filename_from_url(target_url, "downloaded_media.bin"))
    source_preview = dict(media.get("preview") or {})

    if media_type == "image":
        mime = str(media.get("mime_type") or "image/jpeg")
        if not mime.startswith("image/"):
            mime = "image/jpeg"
        source_preview["kind"] = "image"
        source_preview["page_url"] = source_preview.get("page_url") or target_url
        source_preview["data_url"] = _bytes_to_data_url(payload, mime)
        if not source_preview.get("url"):
            source_preview["url"] = target_url
        return _analyze_evidence_bytes(
            image_bytes=payload,
            explain=explain,
            evidence_level=evidence_level,
            fusion_w=fusion_w,
            source_preview=source_preview,
            input_media_type="image",
        )

    source_preview["kind"] = "video"
    source_preview["page_url"] = source_preview.get("page_url") or target_url
    if not source_preview.get("url"):
        source_preview["url"] = target_url
    return _analyze_video_bytes(
        content=payload,
        filename=filename,
        source_preview=source_preview,
    )


# =========================
# Image inference
# =========================
@app.post("/analyze")
async def analyze_image(file: UploadFile = File(...)):
    image_bytes = await file.read()

    try:
        score, pixel_score, freq_score, preprocessed = detector.predict(
            image_bytes,
            include_preprocess=True,
        )
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Model Inference Error: {e}")

    analysis_result = build_analysis_result(
        score, pixel_score, freq_score,
        real_mean=REAL_MEAN, real_std=REAL_STD
    )
    if preprocessed is not None:
        analysis_result["preprocessed"] = preprocessed

    stored_result = dict(analysis_result)
    stored_result.pop("preprocessed", None)
    return store_result_and_make_response(analysis_result, stored_result=stored_result)


# =========================
# Video inference
# =========================
def _analyze_video_bytes(
    content: bytes,
    filename: str,
    source_preview: Optional[Dict[str, Any]] = None,
) -> dict:
    video_hash = sha256_bytes(content)
    video_cache_key = f"cache:video:{video_hash}"

    cached = redis_get_json(redis_db, video_cache_key)
    if cached is not None and has_frame_series(cached, "video_frame_pixel_scores") and has_frame_series(cached, "video_frame_freq_scores"):
        cached_response = dict(cached)
        cached_response["input_media_type"] = "video"
        if source_preview:
            cached_response["source_preview"] = source_preview
        return store_result_and_make_response(cached_response)

    suffix = os.path.splitext(filename or "")[1] or ".mp4"
    tmp_path = None

    try:
        with tempfile.NamedTemporaryFile(delete=False, suffix=suffix) as tmp:
            tmp_path = tmp.name
            tmp.write(content)

        frames, meta = video_to_uniform_sampled_frames(
            tmp_path,
            max_side=VIDEO_MAX_SIDE,
            min_frames=VIDEO_MIN_FRAMES,
            max_frames=VIDEO_MAX_FRAMES_CAP,
            frames_per_minute=VIDEO_FRAMES_PER_MINUTE,
        )
        if len(frames) == 0:
            raise HTTPException(status_code=400, detail="ë¹„ë””ì˜¤ì—ì„œ í”„ë ˆì„ì„ ì¶”ì¶œí•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")

        if source_preview is not None and not source_preview.get("thumbnail_data_url"):
            try:
                source_preview["thumbnail_data_url"] = _frame_to_preview_data_url(frames[0])
            except Exception:
                pass

        scores, pixel_scores, freq_scores = [], [], []
        successful_frames = []
        successful_frame_indices = []
        failed = 0

        for frame_idx, fr in enumerate(frames):
            try:
                score, p_score, f_score, _ = detector.predict_from_bgr(
                    fr,
                    include_preprocess=False,
                )
                scores.append(score)
                pixel_scores.append(p_score)
                freq_scores.append(f_score)
                successful_frames.append(fr)
                successful_frame_indices.append(frame_idx)
            except Exception:
                failed += 1
                continue

        if len(scores) == 0:
            raise HTTPException(
                status_code=500,
                detail=f"ëª¨ë“  í”„ë ˆì„ ì¶”ë¡  ì‹¤íŒ¨ (sampled={len(frames)}, failed={failed})."
            )

        video_score, trimmed_meta = trimmed_mean_confidence(
            scores,
            trim_ratio=VIDEO_TRIM_RATIO,
        )
        video_pixel = aggregate_scores(pixel_scores, mode=AGG_MODE_VIDEO, topk=TOPK)
        video_freq = aggregate_scores(freq_scores, mode=AGG_MODE_VIDEO, topk=TOPK)

        if video_score is None:
            raise HTTPException(status_code=500, detail="ì˜ìƒ ì ìˆ˜ ì§‘ê³„ ì‹¤íŒ¨")

        analysis_result = build_analysis_result(
            video_score, video_pixel, video_freq,
            real_mean=REAL_MEAN, real_std=REAL_STD
        )
        analysis_result["video_representative_confidence"] = round(float(video_score), 2)
        analysis_result["video_frame_confidences"] = [round(float(s), 2) for s in scores]
        analysis_result["video_frame_pixel_scores"] = [round(float(s), 2) for s in pixel_scores]
        analysis_result["video_frame_freq_scores"] = [round(float(s), 2) for s in freq_scores]

        analysis_result["video_meta"] = {
            "used_frames": len(scores),
            "failed_frames": failed,
            "agg_mode": "Trimmed Mean 10 Percent",
            "pixel_freq_agg_mode": AGG_MODE_VIDEO,
            "topk": TOPK,
        }
        analysis_result["video_meta"].update(trimmed_meta)
        analysis_result["video_meta"].update(meta)

        representative_payload = None
        try:
            if successful_frames and detector.pixel_model is not None and detector.freq_model is not None:
                score_arr = np.asarray(scores, dtype=np.float32)
                rep_pos = int(np.argmin(np.abs(score_arr - float(video_score))))
                rep_frame_bgr = successful_frames[rep_pos]
                rep_sample_index = int(successful_frame_indices[rep_pos])
                rep_score = float(scores[rep_pos])

                rep_faces = detect_faces_with_aligned_crops(
                    image_bgr=rep_frame_bgr,
                    margin=0.15,
                    target_size=224,
                    max_faces=1,
                    prioritize_frontal=False,
                )

                if rep_faces:
                    rep_cam = GradCAM(detector.pixel_model, get_cam_target_layer(detector.pixel_model))
                    try:
                        rep_out = build_evidence_for_face(
                            face_rgb_uint8=rep_faces[0]["crop_rgb"],
                            landmarks=rep_faces[0]["landmarks"],
                            rgb_model=detector.pixel_model,
                            freq_model=detector.freq_model,
                            cam=rep_cam,
                            fusion_w=0.5,
                            evidence_level="mvp",
                        )
                    finally:
                        rep_cam.close()

                    representative_payload = {
                        "sample_index": rep_sample_index,
                        "frame_score": round(rep_score, 2),
                        "target_score": round(float(video_score), 2),
                        "abs_diff": round(abs(rep_score - float(video_score)), 2),
                        "assets": rep_out.get("assets", {}),
                        "evidence": rep_out.get("evidence", {}),
                        "explanation": explain_from_evidence(
                            evidence=rep_out.get("evidence", {}),
                            score=rep_out.get("score", {}),
                            media_mode_hint="video",
                            use_openai=True,
                        ),
                    }
        except Exception:
            representative_payload = None

        if representative_payload is not None:
            analysis_result["representative_analysis"] = representative_payload

        ai_comment = generate_video_ai_comment(
            final_scores=[float(s) for s in scores],
            pixel_scores=[float(s) for s in pixel_scores],
            freq_scores=[float(s) for s in freq_scores],
            is_fake=bool(analysis_result.get("is_fake")) if isinstance(analysis_result.get("is_fake"), bool) else None,
        )
        ai_comment_source = "openai" if ai_comment else "rule_based"
        if not ai_comment:
            if bool(analysis_result.get("is_fake")):
                ai_comment = "ì˜ìƒ ì „ì²´ íë¦„ì„ ë³´ë©´ ì¡°ì‘ ê°€ëŠ¥ì„±ì´ ì¡°ê¸ˆ ë” ë†’ê²Œ ë³´ì…ë‹ˆë‹¤. ì•„ë˜ ê·¼ê±°ë¥¼ í•¨ê»˜ í™•ì¸í•´ ì£¼ì„¸ìš”."
            else:
                ai_comment = "ì˜ìƒ ì „ì²´ íë¦„ì„ ë³´ë©´ ì›ë³¸ì¼ ê°€ëŠ¥ì„±ì´ ì¡°ê¸ˆ ë” ë†’ê²Œ ë³´ì…ë‹ˆë‹¤. ì•„ë˜ ê·¼ê±°ë¥¼ í•¨ê»˜ í™•ì¸í•´ ì£¼ì„¸ìš”."
        analysis_result["ai_comment"] = ai_comment
        analysis_result["ai_comment_source"] = ai_comment_source
        analysis_result["input_media_type"] = "video"
        if source_preview:
            analysis_result["source_preview"] = source_preview

        cache_payload = dict(analysis_result)
        cache_payload.pop("source_preview", None)
        redis_set_json(redis_db, video_cache_key, cache_payload, ex=CACHE_TTL_SEC)

        return store_result_and_make_response(analysis_result)

    finally:
        if tmp_path and os.path.exists(tmp_path):
            try:
                os.remove(tmp_path)
            except Exception:
                pass


@app.post("/api/analyze-video")
@app.post("/analyze-video")
async def analyze_video(file: UploadFile = File(...)):
    content = await file.read()
    return _analyze_video_bytes(content=content, filename=file.filename or "upload.mp4")


@app.get("/get-result/{token}")
async def get_analysis_result(token: str):
    data = redis_get_json(redis_db, f"res:{token}")
    if data is None:
        raise HTTPException(status_code=404, detail="ê²°ê³¼ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    return data
